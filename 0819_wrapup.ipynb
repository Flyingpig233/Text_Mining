{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.74 s\n",
      "Wall time: 126 ms\n",
      "Wall time: 98.7 ms\n",
      "Wall time: 154 ms\n"
     ]
    }
   ],
   "source": [
    "folder_path = r'C:\\Users\\Yijun.Wan\\OneDrive - Wolters Kluwer\\desktop\\version_extract'\n",
    "%time sf1 = pd.read_csv(os.path.join(folder_path, 'data\\SF_Comments.csv'))\n",
    "%time sf2 = pd.read_csv(os.path.join(folder_path, 'data\\SF_Comments_Apr28Jun05.csv'))\n",
    "%time sf3 = pd.read_csv(os.path.join(folder_path, 'data\\SF_Comments_June28_July31.csv'))\n",
    "%time sf4 = pd.read_csv(os.path.join(folder_path, 'data\\SF_Comments_May30_June30.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.046184"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([sf1, sf2, sf3, sf4], axis=0, ignore_index = True)\n",
    "df2 = df[df.comment.notnull()]\n",
    "comments = df2.comment\n",
    "[df.shape, len(comments)]\n",
    "## 1 billion records\n",
    "len(comments)/1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>lower_clean</th>\n",
       "      <th>Alphabets</th>\n",
       "      <th>c_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>663</td>\n",
       "      <td>rg</td>\n",
       "      <td>RG</td>\n",
       "      <td>10360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>819</td>\n",
       "      <td>tng</td>\n",
       "      <td>TNG</td>\n",
       "      <td>5659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>309</td>\n",
       "      <td>fs</td>\n",
       "      <td>FS</td>\n",
       "      <td>3669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>208</td>\n",
       "      <td>df</td>\n",
       "      <td>DF</td>\n",
       "      <td>1072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228</td>\n",
       "      <td>dpm</td>\n",
       "      <td>DPM</td>\n",
       "      <td>1027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 lower_clean Alphabets   c_id\n",
       "0         663          rg        RG  10360\n",
       "1         819         tng       TNG   5659\n",
       "2         309          fs        FS   3669\n",
       "3         208          df        DF   1072\n",
       "4         228         dpm       DPM   1027"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_path = r'C:\\Users\\Yijun.Wan\\OneDrive - Wolters Kluwer\\desktop\\version_extract'\n",
    "lookup_abc = pd.read_csv(os.path.join(folder_path,'lookup\\lookup_0820.csv'))\n",
    "#lookup2 = pd.read_csv(os.path.join(folder_path,'lookup\\lookup_0820.csv'))\n",
    "lookup_abc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lower_clean</th>\n",
       "      <th>Alphabets</th>\n",
       "      <th>c_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rg</td>\n",
       "      <td>RG</td>\n",
       "      <td>10360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tng</td>\n",
       "      <td>TNG</td>\n",
       "      <td>5659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fs</td>\n",
       "      <td>FS</td>\n",
       "      <td>3669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>df</td>\n",
       "      <td>DF</td>\n",
       "      <td>1072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dpm</td>\n",
       "      <td>DPM</td>\n",
       "      <td>1027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lower_clean Alphabets   c_id\n",
       "0          rg        RG  10360\n",
       "1         tng       TNG   5659\n",
       "2          fs        FS   3669\n",
       "3          df        DF   1072\n",
       "4         dpm       DPM   1027"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup_abc.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "lookup_abc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_path = os.path.join(folder_path,'lookup\\SomeVersions.xlsx')\n",
    "table = pd.read_excel(lookup_path, sheet_name = 'Sheet13')\n",
    "# run only once\n",
    "versions = table.drop(index=0)['Versions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(series, regx = None, show_examples = False):\n",
    "    # Input data need to be pd.Series\n",
    "    \n",
    "    ## define matching criteria\n",
    "    if regx is None:\n",
    "        full_regx = '\\s.?[A-Za-z_]{3,}.?[0-9]{1,2}[.][0-9]{1,2}[.0-9]*.?\\s'\n",
    "        other_regx = '\\s.?[0-9]{1,2}[.\\s]?[0-9]{1,2}[.0-9]*.?\\s'\n",
    "        #regular_expression = '\\s.?[A-Z]{1}[A-Za-z_]{1,}.?[0-9]{1,2}[.][0-9]{1,2}[.0-9]*.?\\s|\\s.?[0-9]{1,2}[.][0-9]{1,2}[.0-9]*.?\\s'\n",
    "        regular_expression = r'\\s.?[A-Z]{1}[A-Za-z_]{1,}.?[0-9]{1,2}[.][0-9]{1,2}[.0-9]*.?\\s|\\s[^a-zA-Z]?[0-9]{1,2}[.][0-9]{1,2}[.0-9]*.?\\s'\n",
    "    else:\n",
    "        regular_expression = regx\n",
    "    \n",
    "    new_series = pd.Series([re.sub('\\s[vV]ersion is|\\s[vV]ersion|[vV]ersion', '', x) for x in series],index = series.index)\n",
    "    \n",
    "        # get a match object\n",
    "        # matches = [re.search(regular_expression ,str(x)) for x in series]\n",
    "        \n",
    "    matches = pd.Series([re.findall(regular_expression ,str(x)) for x in new_series],\n",
    "                        index = new_series.index)\n",
    "\n",
    "    ind = [len(x)!=0 for x in matches]\n",
    "    extracted = matches[ind]\n",
    "    extracted.name = 'Matched Results'\n",
    "\n",
    "    extract_final = pd.DataFrame(extracted)\n",
    "    extract_final['Matched Num'] =  extract_final['Matched Results'].apply(len)\n",
    "    \n",
    "    \n",
    "    if show_examples:\n",
    "        print('Extracted samples:')\n",
    "        for i, info in extract_final.head(3).iteritems():\n",
    "            print('-'*20 + '{}'.format(i) + '-'*20)\n",
    "            print(info)\n",
    "    # output series\n",
    "    \n",
    "    return extract_final\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_split(extract_df):\n",
    "    ## split the lst in 'Matched Results'\n",
    "    col_id = extract_df.index.values.repeat(extract_df['Matched Num'])\n",
    "    col_version = list(chain(*list(extract_df['Matched Results'])))\n",
    "    extract_break = pd.DataFrame({'c_id':col_id, 'extract_info': col_version})\n",
    "    \n",
    "    # ma change the original extract_info\n",
    "    extract_break['extract_info'] = extract_break['extract_info'].apply(lambda x: re.sub('[^a-zA-Z0-9.]', '', x))\n",
    "    \n",
    "    return extract_break\n",
    "\n",
    "\n",
    "\n",
    "def text_split(string):\n",
    "    # input is a string \n",
    "    \n",
    "    ## clean the unrelated character which will be different from \n",
    "    x = re.sub('[^A-Za-z0-9.]+', \"\", string)\n",
    "    ind = x[0] in set(['0','1','2','3','4','5','6','7','8','9'])\n",
    "    if ind:\n",
    "        return np.nan, x\n",
    "    else:\n",
    "                # slice index\n",
    "        start = re.search('\\d',x).span()[0]\n",
    "        #p1 = re.sub('[^A-Za-z]+', \"\", x[:start])\n",
    "        p1 = x[:start]\n",
    "        p2 = x[start:]\n",
    "        return p1, p2\n",
    "\n",
    "    \n",
    "    \n",
    "def words_near(comment_string, extract, string, search_num = 10, lower=True):\n",
    "    \n",
    "    comment =  re.sub('\\s[vV]ersion is|\\s[vV]ersion|[vV]ersion', '', comment_string)\n",
    "    cmt = [re.sub('[^a-zA-Z0-9.]', '', x) for x in re.split('\\s|\\n', comment)]\n",
    "    #cmt = re.split(r'\\s|\\n', comment_string)\n",
    "    length = len(cmt)\n",
    "    \n",
    "    if (extract in cmt):\n",
    "        p_id = cmt.index(extract)\n",
    "        \n",
    "        start = re.search('\\d',extract).span()[0]\n",
    "        new_extract = extract[:start]\n",
    "        cmt[p_id] = new_extract\n",
    "        \n",
    "    elif (string in cmt):\n",
    "        p_id = cmt.index(string)\n",
    "    else:\n",
    "        return {}\n",
    "    # not enough words before\n",
    "    l_end = p_id < search_num\n",
    "    # not enough words after\n",
    "    r_end = (length - p_id) < 5\n",
    "    \n",
    "    if l_end & r_end:\n",
    "        cmt_sub = cmt\n",
    "    elif l_end:\n",
    "        cmt_sub = cmt[:p_id + 5]\n",
    "        \n",
    "    elif r_end:\n",
    "        cmt_sub = cmt[p_id - search_num:]\n",
    "    else:\n",
    "        cmt_sub = cmt[p_id - search_num: p_id + 5]\n",
    "        \n",
    "    cmt_sub_lower = [re.sub('[^a-z]+', \"\", x.lower()) for x in cmt_sub]\n",
    "    cmt_sub = [re.sub('[^A-Za-z]+', \"\", x) for x in cmt_sub]\n",
    "    \n",
    "    if lower:\n",
    "        return set(cmt_sub_lower)\n",
    "    else:\n",
    "        return set(cmt_sub)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def find_alphabets(words_near,potential, lower=False):\n",
    "    if len(words_near)==0:\n",
    "        return set({})\n",
    "    words_near = set(words_near)- set({'Was', 'WAs','was', 'be'})\n",
    "    #s1 = set(['IE', 'BE', 'WAS']).intersection(set(words_near))\n",
    "    \n",
    "    if lower:\n",
    "        a = set([x.lower() for x in words_near])\n",
    "    else:\n",
    "        a = set(words_near)\n",
    "        \n",
    "    b = set(potential)\n",
    "    s2 = a.intersection(b)\n",
    "    \n",
    "    return s2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(comments, lookup):\n",
    "    regx = None\n",
    "    show_examples = False\n",
    "    search_num = 10\n",
    "    \n",
    "    \n",
    "    # series comments\n",
    "    o1 = extract(comments)\n",
    "    \n",
    "    # split list\n",
    "    o1_break = extract_split(o1)\n",
    "    \n",
    "    # split info\n",
    "    txt_split =  o1_break['extract_info'].apply(text_split)\n",
    "    o1_break['Alphabets'] = list(txt_split.apply(lambda x: x[0]))\n",
    "    o1_break['Digits'] = list(txt_split.apply(lambda x: x[1]))\n",
    "    \n",
    "    \n",
    "    ## 'lower': lower alphabets after cleaning\n",
    "    o1_break['lower'] = o1_break['Alphabets'].dropna().apply(lambda x: re.sub('[^a-z]+', \"\", x.lower()))\n",
    "    \n",
    "    ## no version digits start with '0'\n",
    "    filt1 = o1_break['Digits'].apply(lambda x: x[0]=='0')  \n",
    "    mm = o1_break[~filt1]\n",
    "    \n",
    "    \n",
    "    ## \n",
    "    m1 = mm[mm['lower'].isin(set(lookup['lower_clean']))]\n",
    "    m2 = mm[~mm['lower'].isin(set(lookup['lower_clean']))]\n",
    "    \n",
    "    ## map back\n",
    "    m1['versions_1'] = m1['Alphabets']+\" \"+ m1['Digits']\n",
    "    mm1 = m1[~m1.duplicated(['c_id', 'Digits', 'lower'], keep='first')]\n",
    "    mm1_g = mm1.groupby('c_id')['versions_1'].apply(lambda x: ','.join(x)).reset_index()\n",
    "    \n",
    "    Comments = pd.DataFrame({'Comment':comments})\n",
    "    Comments = Comments.join(mm1_g.set_index('c_id'))\n",
    "    \n",
    "    \n",
    "    ## search words\n",
    "    m2f = m2.copy()\n",
    "    m2f = m2f[~m2f.duplicated(['c_id', 'Digits'], keep='first')]\n",
    "    m2f['comment'] = m2['c_id'].map(comments)\n",
    "    \n",
    "    m2f_words = m2f[['comment','extract_info', 'Digits']].apply(lambda x: words_near(*x, lower= False), axis=1)\n",
    "    m2f_words.name = 'words near'\n",
    "    m2f_new = m2f.join(m2f_words)\n",
    "    \n",
    "    mt1 = m2f_new['words near'].apply(lambda x: find_alphabets(x, lookup['lower_clean'], lower=True))\n",
    "    mt2 = [set(lookup[lookup['lower_clean'].isin(x)]['Alphabets']) for x in mt1]\n",
    "    m2f_new['Alphabets2'] = mt2\n",
    "    m2f_new['versions_2'] = m2f_new[['Alphabets2', 'Digits']].apply(lambda x: list(set(map(lambda a:a[0] + ' ' + a[1] , zip(list(x['Alphabets2']),list(np.repeat(x['Digits'],len(x['Alphabets2'])))) ))), axis=1)\n",
    "    \n",
    "    ind_fill_digits = m2f_new['versions_2'].apply(lambda x:len(x))==0\n",
    "    m2f_new['versions_2'][ind_fill_digits] = m2f_new['Digits'][ind_fill_digits].apply(lambda x:[x])\n",
    "    \n",
    "    h_lower = m2f_new.groupby('c_id')['versions_2'].apply(list).reset_index()\n",
    "    h_lower['versions_2'] =  h_lower['versions_2'].apply(lambda x:list(chain(*x)))\n",
    "    Comments2 = Comments.join(h_lower.set_index('c_id'))\n",
    "    \n",
    "    return Comments2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yijun.Wan\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Yijun.Wan\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 40s\n"
     ]
    }
   ],
   "source": [
    "%time oo2 = main(comments, lookup_abc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>versions_1</th>\n",
       "      <th>versions_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>STATUS: OPEN =&gt; User Response Requested</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8/2/05: m.bolding\\nCan this issue be closed or...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Remain open banks are still requesting some ty...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USER ESCALATION &gt;&gt; HIGH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USER ESCALATION &gt;&gt; Emergency/Production Impact</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment versions_1 versions_2\n",
       "0            STATUS: OPEN => User Response Requested        NaN        NaN\n",
       "1  8/2/05: m.bolding\\nCan this issue be closed or...        NaN        NaN\n",
       "2  Remain open banks are still requesting some ty...        NaN        NaN\n",
       "3                            USER ESCALATION >> HIGH        NaN        NaN\n",
       "4     USER ESCALATION >> Emergency/Production Impact        NaN        NaN"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oo2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>versions_1</th>\n",
       "      <th>versions_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>&lt;FONT COLOR=\"\"000000\"\"&gt;&lt;B&gt;From: Wood, Paul [ma...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[FIRE 2.20, FIRE 7.30.1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>=&gt; http://fsahandbook.info/FSA/html/handbook/B...</td>\n",
       "      <td>CA 2.2,BIPRU 14.2.1,BIPRU 14.2.13,BIPRU 14.3.,...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>FYI: we still go for solution 2.  Solution 1 w...</td>\n",
       "      <td>BIPRU 14.2.2,BIPRU 14.2.13,BIPRU 14.4,BIPRU 14.3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Hello Sir,\\n          Request to give us the e...</td>\n",
       "      <td>FRS 1.3.8,FRR 2.6.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Philip,\\nis this on a 3.0 database? This check...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[3.0, 3.0s]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Comment  \\\n",
       "47  <FONT COLOR=\"\"000000\"\"><B>From: Wood, Paul [ma...   \n",
       "64  => http://fsahandbook.info/FSA/html/handbook/B...   \n",
       "81  FYI: we still go for solution 2.  Solution 1 w...   \n",
       "87  Hello Sir,\\n          Request to give us the e...   \n",
       "94  Philip,\\nis this on a 3.0 database? This check...   \n",
       "\n",
       "                                           versions_1  \\\n",
       "47                                                NaN   \n",
       "64  CA 2.2,BIPRU 14.2.1,BIPRU 14.2.13,BIPRU 14.3.,...   \n",
       "81   BIPRU 14.2.2,BIPRU 14.2.13,BIPRU 14.4,BIPRU 14.3   \n",
       "87                                FRS 1.3.8,FRR 2.6.8   \n",
       "94                                                NaN   \n",
       "\n",
       "                  versions_2  \n",
       "47  [FIRE 2.20, FIRE 7.30.1]  \n",
       "64                       NaN  \n",
       "81                       NaN  \n",
       "87                       NaN  \n",
       "94               [3.0, 3.0s]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_2 = oo2['versions_2'].isnull()\n",
    "ind_1 = oo2['versions_1'].isnull()\n",
    "\n",
    "df3 = oo2[~(ind_1 & ind_2)]\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv(r'C:\\Users\\Yijun.Wan\\OneDrive - Wolters Kluwer\\desktop\\version_extract\\output\\0820_versions_check.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "77042/df3.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
